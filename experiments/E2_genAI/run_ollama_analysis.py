import csv
from collections import Counter, defaultdict
import ollama
from pathlib import Path



current_dir = Path(__file__).resolve().parent
e1_dir = current_dir.parent / "E1_cluster"
e1_output_csv = e1_dir / "output_bertopic_clusters.csv"

# ================= CONFIGURA√á√ÉO OLLAMA =================
OLLAMA_MODEL = "llama3:latest" 

def gerar_interpretacao_ollama(topic_id, termos, exemplos, stats):
    
    lista_exemplos = "\n".join([f"- {ex}" for ex in exemplos])
    
    prompt_sistema = """Voc√™ √© um analista s√™nior de opera√ß√µes industriais. 
Sua tarefa √© analisar grupos de problemas e criar resumos acion√°veis para gestores.
Seja direto e t√©cnico."""

    prompt_usuario = f"""
AN√ÅLISE DE CLUSTER (T√ìPICO {topic_id})

DADOS:
- Total relatos: {stats['count']}
- Setor: {stats['sector']}
- Termos t√©cnicos: {', '.join(termos)}

EXEMPLOS REAIS:
{lista_exemplos}

TAREFA:
Crie um resumo estruturado EXATAMENTE neste formato:
Label: [Nome curto, m√°x 5 palavras]
Resumo: [Explica√ß√£o do problema e impacto, m√°x 2 frases]
A√ß√£o: [Uma a√ß√£o pr√°tica sugerida]
"""

    print(f"   ‚Ü≥ ü¶ô Enviando T√≥pico {topic_id} para Llama 3...")
    try:
        response = ollama.chat(model=OLLAMA_MODEL, messages=[
            {'role': 'system', 'content': prompt_sistema},
            {'role': 'user', 'content': prompt_usuario},
        ])
        return response['message']['content']
    except Exception as e:
        return f"Erro Ollama: {str(e)}"

def main():

    print("üì¶ Carregando clusters j√° gerados no E1 (sem re-treinar)...")

    # Usamos o output consolidado do E1 para evitar re-treinar o BERTopic.
    # O CSV j√° cont√©m o topic_id e termos principais por relato.
    if not e1_output_csv.exists():
        raise FileNotFoundError(f"‚ùå CSV do E1 n√£o encontrado em {e1_output_csv}")

    clusters = defaultdict(list)
    topic_terms = defaultdict(list)
    topic_sectors = defaultdict(list)

    with e1_output_csv.open(newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            topic_id = int(row["topic_id"])
            texto = row["texto"].strip()
            setor = row.get("setor", "N/A").strip() or "N/A"
            terms = [t.strip() for t in row.get("top_terms", "").split(",") if t.strip()]

            clusters[topic_id].append(texto)
            topic_terms[topic_id].append(terms)
            topic_sectors[topic_id].append(setor)

    # 3. Loop de Interpreta√ß√£o com Ollama
    print(f"\n‚ö° Iniciando infer√™ncia no {OLLAMA_MODEL}...")

    # Arquivo de sa√≠da na pasta E2
    output_file = Path("relatorio_ia_generativa.md")
    
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("# Relat√≥rio de Interpreta√ß√£o Autom√°tica (Llama 3)\n\n")
        
        for topic_id in sorted(clusters.keys()):
            if topic_id == -1:
                continue  # Pula ru√≠do

            exemplos = clusters[topic_id][:8]  # Limita a 8 exemplos

            # Consolida termos principais a partir do CSV do E1
            termos_flat = [t for terms in topic_terms[topic_id] for t in terms]
            termos = [t for t, _ in Counter(termos_flat).most_common(6)]

            setor_counts = Counter(topic_sectors[topic_id])
            setor = setor_counts.most_common(1)[0][0] if setor_counts else "N/A"
            stats = {'count': len(clusters[topic_id]), 'sector': setor}

            # Chama IA com dados j√° prontos do E1
            resultado = gerar_interpretacao_ollama(topic_id, termos, exemplos, stats)

            # Escreve no arquivo e na tela
            bloco = f"## T√≥pico {topic_id}\n{resultado}\n\n---\n"
            print(bloco)
            f.write(bloco)

    print(f"\n‚úÖ Conclu√≠do! Relat√≥rio salvo em {output_file.resolve()}")

if __name__ == "__main__":
    main()
